{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9915632",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027dde9",
   "metadata": {},
   "source": [
    "## 1.1 Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d18e3e",
   "metadata": {},
   "source": [
    "## 1.2 Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8348c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fc77bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow dependencies - functional API\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Layer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6685aba",
   "metadata": {},
   "source": [
    "## 1.3 Create Folder Strutures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66689ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce56a83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the directories\n",
    "os.makedirs(POS_PATH, exist_ok=True)\n",
    "os.makedirs(NEG_PATH, exist_ok=True)\n",
    "os.makedirs(ANC_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82926791",
   "metadata": {},
   "source": [
    "# 2. Collect Postives and Anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5d77e8",
   "metadata": {},
   "source": [
    "## 2.1 Retrieve Labelled Faces in the Wild Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10142f",
   "metadata": {},
   "source": [
    "Installing another package - retrieves the required dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939e7657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Using cached kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/deepface/lib/python3.9/site-packages (from kagglehub) (25.0)\n",
      "Collecting pyyaml (from kagglehub)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/deepface/lib/python3.9/site-packages (from kagglehub) (2.32.3)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/deepface/lib/python3.9/site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/deepface/lib/python3.9/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/deepface/lib/python3.9/site-packages (from requests->kagglehub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/deepface/lib/python3.9/site-packages (from requests->kagglehub) (2025.4.26)\n",
      "Using cached kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, pyyaml, kagglehub\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [kagglehub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed kagglehub-0.3.12 pyyaml-6.0.2 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104c35e4",
   "metadata": {},
   "source": [
    "Using Kaggles API to download the dataset locally to your computer.\n",
    "\n",
    "You may need to create a Kaggle Account and create an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04362d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/deepface/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/lfw-dataset?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112M/112M [00:04<00:00, 24.7MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/ethanvillalovoz/.cache/kagglehub/datasets/jessicali9530/lfw-dataset/versions/4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jessicali9530/lfw-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37d923b",
   "metadata": {},
   "source": [
    "The downloaded dataset was stored in my .cache directory of my machine.\n",
    "\n",
    "Moves it to the current working directory you are coding this project in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c9ba9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset moved to: /Users/ethanvillalovoz/Desktop/deepface-oneshot-paper-reimplementation/data/lfw-dataset\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# Source path (where KaggleHub downloaded the dataset)\n",
    "src_path = \"/Users/ethanvillalovoz/.cache/kagglehub/datasets/jessicali9530/lfw-dataset/versions/4\"\n",
    "\n",
    "# Destination path (your project directory, e.g., 'data/lfw-dataset')\n",
    "dst_path = os.path.join(os.getcwd(), \"data\", \"lfw-dataset\")\n",
    "\n",
    "# Move the directory\n",
    "if not os.path.exists(dst_path):\n",
    "    shutil.move(src_path, dst_path)\n",
    "    print(f\"Dataset moved to: {dst_path}\")\n",
    "else:\n",
    "    print(\"Destination already exists. Remove it first if you want to overwrite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3675658d",
   "metadata": {},
   "source": [
    "Moves all of the images from the dataset into our negative image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory in os.listdir(dst_path):\n",
    "    if directory.startswith(\"lfw-deepfunneled\"):\n",
    "        src_dir = os.path.join(dst_path, directory)\n",
    "        for sub_directory in os.listdir(src_dir):\n",
    "            if directory.startswith(\"lfw-deepfunneled\"):\n",
    "                sub_dir_path = os.path.join(src_dir, sub_directory)\n",
    "                for filename in os.listdir(sub_dir_path):\n",
    "                    filename_path = os.path.join(sub_dir_path, filename)\n",
    "                    for image in os.listdir(filename_path):\n",
    "                        if image.endswith(\".jpg\"):\n",
    "                            image_path = os.path.join(filename_path, image)\n",
    "                            print(f\"Processing image: {image_path}\")\n",
    "                            final_dst_path = os.path.join(NEG_PATH, image)\n",
    "                            print(f\"dst_path: {final_dst_path}\")\n",
    "                            shutil.move(image_path, final_dst_path)\n",
    "                            print(f\"Moved {image_path} to {final_dst_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206abb0c",
   "metadata": {},
   "source": [
    "## 2.2 Collect Positive and Anchor Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d35db8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import uuid library for unique file names\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e8fe5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: AVFoundation didn't find any attached Video Input Devices!\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    }
   ],
   "source": [
    "# Establish connection to the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = frame[120:120+250, 120:120+250, :]  # Crop the frame to a square\n",
    "\n",
    "    # Collect anchor images\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        # Create a unique filename using uuid\n",
    "        imgname = os.path.join(ANC_PATH, f\"{uuid.uuid1()}.jpg\")\n",
    "        # Wrute the image to the anchor path\n",
    "        cv2.imwrite(imgname, frame)\n",
    "\n",
    "    # Collect positive images\n",
    "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "        # Create a unique filename using uuid\n",
    "        imgname = os.path.join(POS_PATH, f\"{uuid.uuid1()}.jpg\")\n",
    "        # Wrute the image to the anchor path\n",
    "        cv2.imwrite(imgname, frame)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "\n",
    "    # Breaking gracefully\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba562f",
   "metadata": {},
   "source": [
    "# 3. Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1dd175",
   "metadata": {},
   "source": [
    "## 3.1 Get Image Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ed7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(os.path.join(ANC_PATH, '*.jpg')).take(300)\n",
    "positive = tf.data.Dataset.list_files(os.path.join(POS_PATH, '*.jpg')).take(300)\n",
    "negative = tf.data.Dataset.list_files(os.path.join(NEG_PATH, '*.jpg')).take(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d172e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
